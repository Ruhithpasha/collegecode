{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744b508a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'Age': [25, np.nan, 35, 40, 29],\n",
    "    'Salary': [50000, 60000, np.nan, 80000, 52000],\n",
    "    'Department': ['Sales', 'Engineering', 'HR', np.nan, 'Sales'],\n",
    "    'Purchased': ['Yes', 'No', 'Yes', 'No', 'Yes']\n",
    "})\n",
    "\n",
    "# Display original dataset\n",
    "print(\"Original Dataset:\\n\")\n",
    "print(data)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('Purchased', axis=1)\n",
    "y = data['Purchased']\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Define preprocessing for numerical data (imputation + standardization)\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Define preprocessing for categorical data (imputation + one-hot encoding)\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_pipeline, numerical_cols),\n",
    "    ('cat', categorical_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "# Fit and transform the features\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Display processed features\n",
    "print(\"\\nProcessed Features (after handling missing values, encoding, and scaling):\\n\")\n",
    "print(X_processed.toarray() if hasattr(X_processed, \"toarray\") else X_processed)\n",
    "\n",
    "# Optionally, show the transformed feature names\n",
    "encoded_feature_names = preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_cols)\n",
    "all_feature_names = numerical_cols + encoded_feature_names.tolist()\n",
    "\n",
    "print(\"\\nProcessed Feature Names:\")\n",
    "print(all_feature_names)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
